#机器学习--一些问题以及思考
##介绍

--------------------------------
* 一般在分类算法中都会给出分类精度作为衡量模型好坏的标准，但在实际项目中我们却几乎不
看这个指标。为什么？因为那不是我们关注的目标。
用户有时真的很关心分类的精度吗？

* “让数据说话”没有错，关键是还要记得另一句话：兼听则明，偏听则暗！如果数据＋工具就
可以解决问题的话，还要人做什么呢？

* model的准确率和样本标注的准确率关系密切。它代表了我们model识别的上界。所以在train之前，先看看我们的上限还是很有帮助的。

* 你通过A,B,C,...方式去get 数据，反过头来若是再把A等作为识别的一列特征，那么必然导致A的权重变大，准确率变得很高。

* 避免过拟合现象的基本方法：正则化方法，regularization。正则化方法你可以理解为，对于选择函数空间的做了一种限制。使得这个函数空间比原来的函数空间小，所以不会把过分拟合的函数选择进入需要的函数空间。加入正则化之后等价于对于一些函数空间的限制

* 交叉验证只是模型选择的一种方法，如果你有模型选择问题，你就可以用交叉验证。例如你做线性回归，你有10个变量，你就有1024个模型需要选择，你就可以使用交叉验证或者AIC(最小信息准则)，做任何一件事情，都会从不同的目的去做，使用交叉验证是从预测的角度去做，使用AIC是从模型的复杂度不模型的拟合角度去做。使用p-value使用假设检验的角度去做，模型选择都是选择方法。

* 最小二乘数学建模等价于高斯噪声最大释然估计统计建模，正则化最小二乘等价于基于高斯噪声的最大化后验概率统计建模。 这里就像我说的，几乎所有的机器学习斱法也许建立之初没有什么统计解释，最后大家发现，都可以通过统计的原理解释 。

* 最小二乘用的是squre loss；svm是hinge loss。

--------------------------------
######（转载本站文章请注明作者和出处 <a href="https://github.com/MangoLiu">MangoLiu</a> ，请勿用于任何商业用途）

