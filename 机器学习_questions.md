#机器学习--一些问题/思考/讨论
##介绍

--------------------------------
* 一般在分类算法中都会给出分类精度作为衡量模型好坏的标准，但在实际项目中我们却几乎不
看这个指标。为什么？因为那不是我们关注的目标。
用户有时真的很关心分类的精度吗？

* “让数据说话”没有错，关键是还要记得另一句话：兼听则明，偏听则暗！如果数据＋工具就
可以解决问题的话，还要人做什么呢？

* model的准确率和样本标注的准确率关系密切。它代表了我们model识别的上界。所以在train之前，先看看我们的上限还是很有帮助的。

* 你通过A,B,C,...方式去get 数据，反过头来若是再把A等作为识别的一列特征，那么必然导致A的权重变大，准确率变得很高。

* 避免过拟合现象的基本方法：正则化方法，regularization。正则化方法你可以理解为，对于选择函数空间的做了一种限制。使得这个函数空间比原来的函数空间小，所以不会把过分拟合的函数选择进入需要的函数空间。加入正则化之后等价于对于一些函数空间的限制

* 交叉验证只是模型选择的一种方法，如果你有模型选择问题，你就可以用交叉验证。例如你做线性回归，你有10个变量，你就有1024个模型需要选择，你就可以使用交叉验证或者AIC(最小信息准则)，做任何一件事情，都会从不同的目的去做，使用交叉验证是从预测的角度去做，使用AIC是从模型的复杂度不模型的拟合角度去做。使用p-value使用假设检验的角度去做，模型选择都是选择方法。

* 最小二乘数学建模等价于高斯噪声最大释然估计统计建模，正则化最小二乘等价于基于高斯噪声的最大化后验概率统计建模。 这里就像我说的，几乎所有的机器学习斱法也许建立之初没有什么统计解释，最后大家发现，都可以通过统计的原理解释 。

* 最小二乘用的是squre loss；svm是hinge loss。

* 数据少时用最大似然方法估计参数会过拟合，而贝叶斯方法认为模型参数有一个先验分布，因此共轭分布在贝叶斯方法中很重要。？

* 后验分布式先验和数据共同作用的结果。随着数据不断增加，参数后验分布的不确定性逐渐减少，朝一个点坍缩。

* 为什么要用Polynomial Fitting(多项式拟合)?有数学依据么，这里牵扯到范函的问题，就是函数所张成的空间，丼一个简单的例子，大家还都记得talyor展式吧：<br>
![talyor展开式](/images/jiqixuexi/ML_talyor.png)<br>
这表明 任意一个函数可以表示成 x的次方之和，也就是任意一个函数可以放到(1,x,x^2,x^3...)
所张成的函数空间，如果是有限个基的话就称为欧式空间。

* 线性model怎么构造,是单层的linear model,还是多层的linear model一直争论不休，BP否定了perceptron 的model，SVM 否定了BP model现在deep learning 又质疑SVM的shallow model，或许这就是machine learning还能前进的动力。？

* 引入基函数后,Linear regression的模型可以表达非线性的东西了，因为基函数可能是非线性的。




--------------------------------
######（转载本站文章请注明作者和出处 <a href="https://github.com/MangoLiu">MangoLiu</a> ，请勿用于任何商业用途）

