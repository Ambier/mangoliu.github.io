#机器学习--回归
##介绍
线性回归属于监督学习的一种，用于模型为连续函数的数值预测。也可以利用回归方程来做二分类。<br>

线性回归其实就是确定一系列最佳参数。显而易见，参数的最后确定和训练样本有关，和假设参数有关，也和损失函数有关。<br>

##简单约定
假设是线性关系：<br>
**h(x)=θ[0]x[0] + θ[1]x[1] +...**<br>
其中θ[i]是我们要估计的参数，x[i]是自变量，即特征；y[i]是因变量，即结果。<br>

我们采用**平方误差和**的形式来作为损失函数:<br>
**J(θ)= 1/2 * {[h(x[0])-y[0]]^2 + [h(x[1])-y[1]]^2 + ...}**<br>
说明:1/2只是为了后面求导计算时方便而特地加上的。<br>

此时，我们的目的就很明确了：利用已有的训练数据，来得到一些系列θ，使J(θ)的值达到最小。<br>

##梯度法
梯度上升法基本思想：要找到某个函数的最大值，最好的方法是沿着该函数的梯度方向探寻。因为这是函数值增长最快的方向。<br>

梯度下降法和上升法的思想是一致的，只是使用的不是加法而是减法。上升法是求最大值，下降法是求最小值。<br>
在此，我们要求最小值，所以我们使用梯度下降法。<br>
![公式1](/images/jiqixuexi/ML_LR_1.png)<br>
![公式2](/images/jiqixuexi/ML_LR_2.png)<br>
这样，梯度下降的公式就变成了这样：<br>
![公式3](/images/jiqixuexi/ML_LR_3.png)<br>

这里的α为**学习速率**，即每次迭代的步长，如果太小则迭代速度过慢，如果太大则因为跨度太大无法有效找到期望的最小值，该值需要根据实际情况进行调整。<br>

我们一次把所有的数据都考虑进来，称作是“**批处理**”：<br>
![公式4](/images/jiqixuexi/ML_LR_4.png)<br>
这样做计算复杂度太高。我们可以使用一种新的方法，一次仅用一个样本来更新回归系数，称之为“**随机梯度上升算法**”。这是一种在线学习算法，进行增量式更新。<br>
主要流程：<br>
```
读取训练数据;
初始所需参数;
while(终止条件)//通常设定为指定循环数目{
    遍历数据集{
        按照偏导数修改参数；
    }
    判断是否收敛{
        收敛，则跳出；
    }
    更改终止条件自变量；
}

```
请看下例python代码：<br>
```python
# -*- coding:utf-8 -*-  
""" 
增量梯度下降 
y=1+0.5x 
"""  
import sys  
  
  
# 训练数据集  
# 自变量x(x0,x1)  
x = [(1,1.15),(1,1.9),(1,3.06),(1,4.66),(1,6.84),(1,7.95)]  
# 假设函数 h(x) = theta0*x[0] + theta1*x[1]  
# y为理想theta值下的真实函数值  
y = [1.37,2.4,3.02,3.06,4.22,5.42]  
  
  
# 两种终止条件  
loop_max = 10000 # 最大迭代次数  
epsilon = 0.0001 # 收敛精度  
  
  
alpha = 0.005 # 步长  
diff = 0 # 每一次试验时当前值与理想值的差距  
error0 = 0 # 上一次目标函数值之和  
error1 = 0 # 当前次目标函数值之和  
m = len(x) # 训练数据条数  
  
  
#init the parameters to zero  
theta = [0,0]  
  
count = 0  
finish = 0  
while count<loop_max:  
    count += 1  
    # 遍历训练数据集，不断更新theta值  
    for i in range(m):  
        # 训练集代入，计算假设函数值h(x)与真实值y的误差值  
        diff = (theta[0]*x[i][0] + theta[1]*x[i][1]) - y[i]  
      
        # 求参数theta，增量梯度下降算法，每次只使用一组训练数据  
        theta[0] = theta[0] - alpha * diff * x[i][0]  
        theta[1] = theta[1] - alpha * diff * x[i][1]  
    # 此时已经遍历了一遍训练集，求出了此时的theta值  
    
    # 判断是否已收敛  
    if abs(theta[0]-error0) < epsilon and abs(theta[1]-error1) < epsilon:  
        print 'h(x) = %f * x0 + %f * x1 '%(theta[0],theta[1]) 
        finish = 1  
    else:  
        error0,error1 = theta  
    if finish:  
        break  
  
print 'FINISH count:%s' % count

```

可以考虑α随着迭代次数的增加，α逐渐减小，但仍要具有影响。即修改步长，不然当接近极值点的时候，若是步长过长，又是只能走直线会导致来回在极值点周围转悠。<br>
为了避免参数的严格下降也可考虑使用模拟退火等算法。<br>

##牛顿法
牛顿法和梯度下降法都是求解无约束最优化问题的常用方法，也是一种迭代算法。
不同的是梯度下降法是利用一阶偏导数，而牛顿法是利用的二阶偏导数。<br>
牛顿法会利用海赛矩阵，即对任意参数求二阶偏导。<br>

牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。<br>
如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。<br>
所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。<br>

从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。<br>

这个二阶导数对算法的影响有两个方面，方向和大小。方向，二阶导数的几何含义是曲率，也就是迭代的时候是考虑到梯度下降的方向的。大小，每次迭代的步长是和陡度成反比的，越陡步长越小，平坦的时候步长越大。(请结合后面的公式来看)<br>

梯度法相当于对原函数的泰勒一阶展开式逐次求极值，牛顿法是对二阶展开式求极值。<br>
如果把Hessian矩阵的逆矩阵看成梯度法的alpha，就会发现它可以看成是一种不断改进下降梯度的梯度法。<br>

牛顿法的迭代公式是：![牛顿法迭代公式](/images/jiqixuexi/ML_NEWTON.png)<br>

这里的二阶偏导，就是我们上面说的海赛矩阵（也可以参考《统计学习方法》李航）<br>
在实际迭代的过程中，需要对这个二阶偏导矩阵求逆矩阵，在计算起来会比较困难。因此会使用拟牛顿法来退而求其次，其基本思想就是用一个n阶矩阵来代替上述的海赛矩阵的逆矩阵。<br>










--------------------------------
问题：<br>
* 如何选择初始点,即初始参数值的确定？<br>
* 最小二乘法和梯度下降法是什么？<br>
* 如何设计终止条件？<br>
* 岭回归<br>
* 牛顿法和拟牛顿法<br>
* 不同的方法之间有何本质区别？<br>
* 随机梯度下降和改进的随机梯度下降。<br>



--------------------------------
######（转载本站文章请注明作者和出处 <a href="https://github.com/MangoLiu">MangoLiu</a> ，请勿用于任何商业用途）

