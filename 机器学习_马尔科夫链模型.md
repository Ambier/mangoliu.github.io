#机器学习_马尔科夫链模型
##介绍
--------------------------------
>马尔科夫模型是一个用于预测的统计模型，在人口，股票等问题上有很多应用。<br>
>马尔科夫过程是一个离散随机过程，在这个过程中，过去的信息对于预测将来是无关的。即只与当前状态有关。（一阶模型，也有N阶马尔科夫模型，表示当前状态仅与之前的N个状态有关，跟再前面的无关。）<br>
>时间和状态都是离散的马尔科夫过程，称为马尔科夫链，记为：![马尔科夫链](/images/jiqixuexi/markov_lian.PNG)<br>
>这样，我们根据上面介绍的，可以得出：![马尔科夫性质](/images/jiqixuexi/markov_xingzhi.PNG)<br>
> 对于有N个状态的一阶马尔科夫模型，每个状态可以转移到另一个状态（包括自己），则共有N^2次状态转移，可以用状态转移矩阵表示。
Pij = P(Xn + 1 = i | Xn = j)，表示其中Pij表示系统在时刻t处于状态j，在下一时刻t+l处于状态i的概率。<br>
>例如：一段文字中名词、动词、形容词出现的情况可以用有3个状态的y一阶马尔科夫模型M表示。状态s1:名词，状态s2:动词，状态s3:形容词。已知状态转移矩阵A，则状态序列O=“名动形名”（假定第一个词为名词）的概率为：
![马尔科夫例子1](/images/jiqixuexi/markov_example1.PNG)<br>
>马尔科夫过程定义了以下三个部分：状态，初始向量，状态转移矩阵。<br>
##隐形马尔科夫模型
--------------------------------
>隐形马尔科夫模型(HMM)是一个用来描述含有隐含未知参数的马尔可夫过程的统计模型。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析。<br>
>HMM是马尔科夫链中的一种，只是它的状态不能直接被观察到，但是可以通过观察向量间接的反映出来，即每一个观察向量由一个具有相应概率密度分布的状态序列产生，又由于每一个状态也是随机分布的，所以HMM是一个双重随机过程。
<br>
>某地只有两种天气：雨天和晴天。某人只做3件事：散步，购物，打扫卫生。
做什么事，跟天气很有关系。<br>
你知道这个地区的总的天气趋势,并且平时知道某人会做的事情。就是说这个隐马尔可夫模型的参数是已知的.<br>
'states = Rainy,Sunny<br>
observations =walk, shop, clean<br>
start_probability =Rainy: 0.6, Sunny: 0.4<br>
transition_probability = {<br>
   Rainy: {Rainy: 0.7, Sunny: 0.3},<br>
   Sunny : {Rainy: 0.4, Sunny: 0.6},<br>
   }<br>
emission_probability = {<br>
   Rainy : {walk: 0.1, shop: 0.4, clean: 0.5},<br>
   Sunny : {walk: 0.6, shop: 0.3, clean: 0.1},<br>
   }<br>
   '<br>
>可以观察到的状态序列和隐藏的状态序列是概率相关的。隐藏的状态和可观察到的状态之间有一种概率上的关系，也就是说某种隐藏状态 H 被认为是某个可以观察的状态 O1 是有概率的，假设为 P(O1 | H)。如果可以观察的状态有3种，那么很显然 P(O1 | H)+P(O2 | H)+ P(O3 | H) = 1。<br>
>HMM是语音识别，人体行为识别，文字识别等领域应用非常广泛。<br>
>已知模型参数，计算某一特定输出序列的概率.通常使用forward算法解决.<br>
>已知模型参数，寻找最可能的能产生某一特定输出序列的隐含状态的序列.通常使用Viterbi算法解决.<br>
>已知输出序列，寻找最可能的状态转移以及输出概率.通常使用Baum-Welch算法以及Reversed Viterbi算法解决.<br>
>如果您已经看到这，只能说声抱歉，因为我找到了一篇写的非常非常的介绍隐性马尔科夫的文章。自惭形愧了，链接如下：[隐马尔可夫模型（HMM）攻略](http://blog.csdn.net/likelet/article/details/7056068)<br>

######（转载本站文章请注明作者和出处 <a href="https://github.com/MangoLiu">MangoLiu</a> ，请勿用于任何商业用途）

